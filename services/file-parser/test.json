{
  "fileName": "test.pdf",
  "pages": [
    {
      "number": 1,
      "content": "DOCKER SWARM",
      "images": []
    },
    {
      "number": 2,
      "content": "INTRODUCTION À DOCKER SWARM\n\n Docker Swarm est l'outil d'orchestration natif de Docker qui permet de gérer un ensemble de nœuds Docker\n\ncomme un cluster. Il simplifie le déploiement, la mise à l'échelle, et la gestion des services conteneurisés sur\nplusieurs hôtes. Swarm utilise une approche déclarative pour la gestion des services, où l'état désiré du cluster est\nspécifié par l'utilisateur.",
      "images": []
    },
    {
      "number": 3,
      "content": "POURQUOI UTILISER DOCKER SWARM ?\n\n Haute disponibilité : Évite le point de défaillance unique\n Mise à l'échelle facile : Déployer plusieurs instances de l'application\n Auto-guérison : Remplace automatiquement les conteneurs défaillants\n\n Gestion simplifiée : Contrôle centralisé via le nœud manager",
      "images": []
    },
    {
      "number": 4,
      "content": "COMPOSANTS CLÉS DE DOCKER SWARM\n\n Nœud Manager : Coordonne le cluster\n Nœud Worker : Exécute les conteneurs\n Service : Définit l'application à déployer (plusieurs réplicas possibles)",
      "images": []
    },
    {
      "number": 5,
      "content": "CRÉATION D'UN CLUSTER SWARM À 2 NŒUDS\n\n\nPrérequis:\n\n\n\nDeux serveurs avec Docker Engine installé\n\n\n\nCommunication réseau entre les serveurs (résolution DNS ou IP)\n\n\n\nPorts ouverts : 2377 (gestion du cluster), 7946 (découverte des nœuds), 4789 (trafic overlay)\n\n\n\nÉtapes:\n\n\n\n1. Initialiser le Swarm sur le nœud Manager :\n\n\n\ndocker swarm init\n\n\n\n2. Joindre un nœud Worker :\n\n\n\ndocker swarm join --token <token> <manager_ip>:2377\n\n\n\n3. Vérifier les nœuds dans le Swarm :\n\n\n\ndocker node ls\n\n\n\nExemple de sortie :\n\n\n\nID | HOSTNAME | STATUS | AVAILABILITY | MANAGER STATUS\n\n\n\nabcd1234 | manager1 | Ready | Active | Leader",
      "images": []
    },
    {
      "number": 6,
      "content": "AJOUT DE NŒUDS AU CLUSTER\n Ajout d'un nouveau nœud Worker :\n 1. Générer le token pour les Workers :\n docker swarm join-token worker\n\n 2. Joindre le nœud Worker au Swarm :\n docker swarm join --token <worker-token> <manager-ip>:2377\n 3. Vérifier que le nœud est ajouté :\n\n docker node ls",
      "images": []
    },
    {
      "number": 7,
      "content": "PROMOTION ET DÉGRADATION DE NŒUDS\n Promotion d'un nœud Worker en Manager :\n Commande :\n\n docker node promote <worker-name>\n Dégradation d'un nœud Manager en Worker :\n Commande :\n\n docker node demote <manager-name>\n Ces actions permettent d'ajuster les rôles dans le cluster en fonction des besoins (équilibrage de charge, maintenance,\n\netc.).",
      "images": []
    },
    {
      "number": 8,
      "content": "DRAINAGE ET SUPPRESSION DE NŒUDS\n Drainage d'un nœud :\n docker node update --availability drain <node-name>\n Le drainage empêche le nœud de recevoir de nouvelles tâches et redistribue celles en cours vers d'autres nœuds.\n Réactivation d'un nœud :\n\n docker node update --availability active <node-name>\n Suppression d'un nœud du cluster :\n docker node rm <node-name> (après avoir quitté le Swarm : docker swarm leave).",
      "images": []
    },
    {
      "number": 9,
      "content": "GESTION DES MANAGERS DANS UN CLUSTER SWARM\n Dans Docker Swarm, un Manager est responsable de la gestion de l'état du cluster.\n Un seul Manager est désigné comme Leader pour prendre les décisions finales.\n\n Docker Swarm utilise l'algorithme de consensus Raft pour assurer la cohérence et l'élection des Managers.\n Le quorum nécessaire est calculé comme (n/2) + 1, où n est le nombre de Managers.\n quorum = (nombre de Managers / 2) + 1\n\n Pour un cluster robuste, il est recommandé d'avoir un nombre impair de Managers et de les distribuer sur\n\nplusieurs zones géographiques.",
      "images": []
    },
    {
      "number": 10,
      "content": "GESTION DES MANAGERS DANS UN CLUSTER SWARM\n\n Tolérance aux Pannes\n\n Le cluster peut tolérer la perte de jusqu'à (n - 1) / 2 nœuds Managers.\n\n Exemple :\n\n Avec 3 Managers : Tolérance à 1 panne.\n Avec 5 Managers : Tolérance à 2 pannes.",
      "images": []
    },
    {
      "number": 11,
      "content": "CRÉATION ET GESTION DES SERVICES SWARM\n\n\nUn service est un ensemble de conteneurs répliqués ou distribués à travers le cluster.\n\n\n\nCréation d'un service avec Nginx (3 réplicas) :\n\n\n\ndocker service create --name my-web --replicas 3 -p 80:80 nginx\n\n\n\nVérification des services :\n\n\n\ndocker service ls\n\n\n\ndocker service ps <service-name>\n\n\n\nMise à jour d'un service (changer l'image) :\n\n\n\ndocker service update --image nginx:latest my-web\n\n\n\nRollback d'un service :\n\n\n\ndocker service rollback my-web",
      "images": []
    },
    {
      "number": 12,
      "content": "TYPES DE SERVICES ET PLACEMENT\n Docker Swarm propose deux types de services :\n Répliqué : Le nombre de réplicas est défini par l'utilisateur.\n Global : Une instance par nœud.\n Création d'un service global :\n docker service create --name my-agent --mode global monitoring-agent\n Pour contrôler le placement des services, utilisez les labels :\n docker node update --label-add type=cpu-intensive <node-name>\n Utilisez des contraintes pour assigner des services à des nœuds spécifiques.\n\n\ndocker node update --label-add type=database worker1\n\n\n\ndocker service create --name db-service --constraint 'node.labels.type == database' mysql",
      "images": []
    },
    {
      "number": 13,
      "content": "DOCKER CONFIG POUR GÉRER LES FICHIERS DE CONFIGURATION\nDocker Config permet de gérer et partager des fichiers de configuration sur tous les nœuds du cluster.\n\n\nCréation d'une configuration :\n\n\n\ndocker config create my_nginx_conf /path/to/nginx.conf\n\n\n\nUtilisation dans un service :\n\n\n\ndocker service create --name my-nginx --config src=my_nginx_conf,target=/etc/nginx/nginx.conf\nnginx\n\nRotation des Configs\n\n\nCréer la Nouvelle Config\n\n\n\n\ndocker config create my_nginx_conf_v2 /path/to/new_nginx.conf\n\nMettre à Jour le Service\n\n\ndocker service update --config-rm my_nginx_conf --config-add\nsrc=my_nginx_conf_v2,target=/etc/nginx/nginx.conf my-nginx",
      "images": []
    },
    {
      "number": 14,
      "content": "DOCKER STACK POUR LE DÉPLOIEMENT D'APPLICATIONS\n\n\nDocker Stack permet de déployer une application composée de plusieurs services via un fichier\ndocker-compose.yml (version 3+).\n\n\n\nDéployer une stack :\n\n\n\ndocker stack deploy -c docker-compose.yml my-stack\n\n\n\nExemple de fichier docker-compose.yml version:\n:\n\n'3.8'\nservices:\nweb:\nimage: nginx\nports:\n\"80:80\"\ndeploy:\nreplicas: 5\nplacement:\nconstraints:\nnode.role == worker",
      "images": []
    },
    {
      "number": 15,
      "content": "DIFFÉRENCES ENTRE DOCKER COMPOSE ET DOCKER STACK\n Docker Stack utilise un fichier docker-compose.yml similaire à Docker Compose, il ajoute des options spécifiques\n\nà Swarm comme :\n Réplicas : nombre d'instances d'un service à déployer sur le cluster.\n Placement : contraintes pour définir sur quels nœuds un service doit s'exécuter.\n Mises à jour progressives (Rolling updates) : définir comment les mises à jour sont appliquées à un service\n\n(parallélisme, délai, rollback).\n Ressources : limitation des ressources CPU et mémoire pour chaque service.\n Tolérance aux pannes (Fault tolerance) : gestion de la résilience des services.",
      "images": []
    },
    {
      "number": 16,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\n\n replicas : Nombre d'instances à exécuter pour le service.\n\nreplicas: 5\n\n\n5 réplicas pour assurer une haute disponibilité.",
      "images": []
    },
    {
      "number": 17,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\nupdate_config : Configurer les mises à jour progressives (rolling updates).\n\n\n\nparallelism : Nombre de conteneurs à mettre à jour simultanément.\n\n\n\ndelay : Temps d'attente entre chaque mise à jour.\n\n\n\nfailure_action : Action à prendre en cas d'échec de mise à jour (rollback, pause, continue).\n\n\n\nmonitor : Temps d'attente avant de considérer la mise à jour comme réussie ou échouée.\n\n\n\nmax_failure_ratio : Ratio d'échec maximal avant de stopper la mise à jour.\n\n\n\n\nCalcul du ratio : si vous avez un service avec 5 réplicas et que vous définissez max_failure_ratio à 0.2, Docker Swarm permettra jusqu'à 1 échec (20 % de\n5) pendant la mise à jour. Si plus de 1 échec se produit, Docker considérera la mise à jour comme échouée et n'appliquera pas les modifications.\n\nExemple :\n\ndeploy:\nreplicas: 3\nupdate_config:\nparallelism: 2\ndelay: 10s\nmonitor: 10s\nfailure_action: rollback\nmax_failure_ratio: 0.3",
      "images": []
    },
    {
      "number": 18,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\nrestart_policy : Définir la politique de redémarrage.\n\n\ncondition : Conditions de redémarrage (on-failure, always, none).\n\n\n\ndelay : Délai avant de redémarrer un conteneur échoué.\n\n\n\nmax_attempts : Nombre maximum de tentatives de redémarrage.\n\n\n\nwindow : Spécifie la durée de la période d'observation. Pendant cette période, Docker enregistre les\néchecs et prend des décisions sur le redémarrage des réplicas en fonction du nombre d'échecs\nqui se produisent dans cette fenêtre.\n\n\nDéfinition de la fenêtre : Par exemple, si vous définissez window à 10s, Docker observera les échecs des réplicas sur une\npériode de 10 secondes.\n\n\n\nLimite des redémarrages : Si, pendant cette période, un service échoue plusieurs fois (par exemple, 3 fois),\nDocker peut décider de ne pas redémarrer immédiatement le service pour éviter un cycle de redémarrages\nincessant. Cela peut être utile pour donner au service le temps de se stabiliser.\n\nrestart_policy:\ncondition: on-failure\nmax_attempts: 3\nwindow: 30s",
      "images": []
    },
    {
      "number": 19,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\n\nresources : Limitation des ressources CPU et mémoire.\n limits : Limites de CPU et de mémoire pour chaque conteneur.\n reservations : Réservation minimale de CPU et de mémoire.\n Exemple :\nresources:\nreservations:\ncpus: '0.25'\nmemory: 256M\nlimits:\ncpus: \"1\"\nmemory: 1024M",
      "images": []
    },
    {
      "number": 20,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\n\nplacement : Contraintes pour définir sur quels nœuds un service doit être exécuté.\n constraints : Utiliser des contraintes pour restreindre un service à des nœuds\n\nspécifiques (node.role == worker ou node.labels.type == db).\n Nb: Les contraintes sont en ET ou non en OU\n Exemple :\nconstraints:\n- node.role == worker\n- node.hostname != swarm-worker01",
      "images": []
    },
    {
      "number": 21,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\n\nhealthcheck : Configurer les vérifications d'état (health check) d'un service.\n test : Commande à exécuter pour vérifier l'état.\n interval : Temps entre chaque vérification.\n\n timeout : Temps maximum pour considérer la vérification comme échouée.\n retries : Nombre de tentatives avant de considérer un service comme non sain.\nhealthcheck:\ntest: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/users\"]\ninterval: 60s\ntimeout: 30s\nretries: 3",
      "images": []
    },
    {
      "number": 22,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\npreferences avec spread :\n La directive preferences est utilisée pour influencer la manière dont Docker Swarm\n\ndistribue les tâches (conteneurs) d'un service sur les différents nœuds.\n\n Avec l'option spread, Docker cherche à répartir les tâches de manière équilibrée en\n\nfonction d'un critère particulier, souvent un label associé aux nœuds.\ndeploy:\nconstraints:\n- node.role == worker\npreferences:\n- spread: node.labels.zone\n\n spread: node.labels.zone indique que Docker Swarm doit essayer de répartir les conteneurs aussi équitablement\n\nque possible entre les nœuds qui ont des labels zone.\n Par exemple, si vous avez trois nœuds étiquetés zone=us-east, zone=us-west et zone=eu-central, Swarm\n\ntentera de distribuer les conteneurs de manière à ce que chaque zone reçoive un nombre équilibré de tâches.",
      "images": []
    },
    {
      "number": 23,
      "content": "OPTIONS SPÉCIFIQUES À SWARM DANS DEPLOY\nendpoint_mode :\n L'option endpoint_mode spécifie le mode d'équilibrage de charge (load balancing) que\n\nDocker Swarm utilisera pour un service particulier.\n\nIl existe deux modes d'équilibrage de charge :\n vip (Virtual IP) : Le mode par défaut. Tous les conteneurs d'un service sont accessibles via\n\nune seule adresse IP virtuelle. Docker Swarm utilise une adresse IP virtuelle partagée\npour équilibrer la charge entre les réplicas d'un service.\n\n dnsrr (DNS Round-Robin) : Utilise un équilibrage de charge au niveau DNS en renvoyant\n\nune liste d'adresses IP des différents réplicas du service. Ce mode est utile pour des\nservices qui gèrent leur propre équilibrage de charge ou dans des cas d'utilisation\nspécifiques comme certains systèmes de cache DNS.\ndeploy:\nendpoint_mode: vip\ndeploy:\nendpoint_mode: dnsrr",
      "images": []
    },
    {
      "number": 24,
      "content": "MISE À JOUR DES SERVICES\n\n Mise à jour de l'image :\n docker service update --image myimage:latest myapp\n\n Rollback en cas d'échec :\n docker service rollback myapp",
      "images": []
    },
    {
      "number": 25,
      "content": "INTRODUCTION À L'ORCHESTRATION\n\n\nL'orchestration est un processus qui permet de gérer et de coordonner les tâches et les actions d'un système complexe.\n\n\n\nDans le contexte de l'informatique, l'orchestration est utilisée pour gérer et coordonner les conteneurs, les machines\nvirtuelles, les clusters et les services dans un environnement distribué.\n\n\n\nLa principale raison d'utiliser l'orchestration est d'améliorer l'agilité, l'évolutivité et la fiabilité des systèmes. En utilisant\nl'orchestration, vous pouvez facilement gérer des centaines ou des milliers de conteneurs ou de machines virtuelles, déployer\ndes applications en quelques minutes, et équilibrer automatiquement la charge sur les différents éléments du système.\n\n\n\nExemples d'utilisation de l'orchestration:\n\n\nDéploiement d'une application en conteneurs sur un cluster de machines\n\n\n\nGérer la scalabilité des instances pour un service web\n\n\n\nAutomatisation de la configuration de machines\n\n\n\nAutomatisation de la découverte de service pour une application distribuée\n\n\n\nGestion de la disponibilité et la tolérance aux pannes d'un système\n\n\n\nIl est important de noter que les systèmes d'orchestration ne se limitent pas aux conteneurs, mais peuvent également gérer des machines\nvirtuelles et des services répartis sur différents systèmes.",
      "images": []
    },
    {
      "number": 26,
      "content": "CONCEPTS DE BASE DE L'ORCHESTRATION\n\n\nConteneurs : Un conteneur est une instance d'une image logicielle, qui permet de lancer une application ou un service dans un environnement isolé.\nLes conteneurs partagent le noyau de l'hôte, ce qui les rend plus légers et plus rapides à démarrer que les machines virtuelles.\n\n\n\nImages : Une image est un fichier qui contient tout ce dont une application a besoin pour s'exécuter, y compris le code source, les bibliothèques,\nles configurations, etc. Les images sont utilisées pour créer des conteneurs.\n\n\n\nDéploiements : Un déploiement décrit comment une application ou un service doit être déployé sur un cluster, y compris le nombre\nd'instances souhaitées, les métadonnées, les stratégies de mise à jour, etc.\n\n\n\nServices : Un service est une abstraction qui permet de diriger le trafic vers un groupe de conteneurs. Les services peuvent être configurés pour\nassurer la disponibilité, l'équilibrage de charge, et la tolérance aux pannes.\n\n\n\nRéseaux : Les réseaux permettent aux conteneurs de communiquer entre eux et avec l'extérieur. Ils peuvent être configurés pour isoler les\nconteneurs, pour créer des sous-réseaux, pour connecter des conteneurs à des services externes, etc.\n\n\n\nVolumes : Les volumes sont des espaces de stockage qui peuvent être utilisés par les conteneurs. Ils permettent de stocker les données de manière\npersistante, même si les conteneurs sont redémarrés ou répliqués.\n\n\n\nIl est important de comprendre que ces concepts de base sont liés les uns aux autres et qu'ils sont utilisés de différentes manières selon le système\nd'orchestration choisi.",
      "images": []
    },
    {
      "number": 27,
      "content": "LES SYSTÈMES D'ORCHESTRATION\n\n\nDocker Swarm : Docker Swarm est un système d'orchestration intégré à Docker qui permet de gérer des conteneurs sur plusieurs\nhôtes. Il permet de créer des clusters de conteneurs, de déployer des applications sur des clusters, de gérer les réseaux et les volumes, et de\ngérer la scalabilité des applications.\n\n\n\nMesos : Mesos est un système d'orchestration distribué qui gère les ressources des machines d'un cluster de manière\ncentralisée. Il permet de gérer des conteneurs et des machines virtuelles, de planifier les tâches sur des machines libres, et de gérer la scalabilité\net la tolérance aux pannes des applications.\n\n\n\nKubernetes : Kubernetes est un système d'orchestration open-source pour les conteneurs qui permet de gérer des clusters de conteneurs à\nl'échelle. Il fournit des fonctionnalités avancées pour la gestion de la scalabilité, de la disponibilité, de la tolérance aux pannes, de\nla sécurité et de la mise à jour des applications. Il est également extensible pour intégrer des fonctionnalités supplémentaires, et peut être\nutilisé avec des outils tels qu'ETCD ou Prometheus pour améliorer les fonctionnalités de base.\n\n\n\nIl est important de noter que chacun de ces systèmes d'orchestration a ses propres avantages et inconvénients et qu'il est important\nde choisir celui qui convient le mieux à vos besoins en fonction de vos exigences en matière de scalabilité, de disponibilité, de\nsécurité, de coûts, etc.\n\n\n\nKubernetes est devenu le système d'orchestration le plus populaire et est utilisé dans de nombreux environnements d'entreprise et Cloud, mais\nd'autres systèmes comme Docker Swarm ou Mesos peuvent être adaptés pour certaines utilisations ou certaines exigences.",
      "images": []
    },
    {
      "number": 28,
      "content": "ORCHESTRATION AVEC DOCKER\n\n\nUtilisation de Docker pour orchestrer des conteneurs : Docker fournit des commandes pour créer et gérer des conteneurs,\ntelles que \"docker run\", \"docker start\", \"docker stop\" pour démarrer, arrêter et supprimer des conteneurs. Il est également possible de\ncréer des conteneurs à partir d'images existantes en utilisant \"docker pull\" pour récupérer des images sur un dépôt d'images et \"docker\ncreate\" pour créer un conteneur à partir de cette image.\n\n\n\nCréation d'images : Les images Docker sont créées en utilisant un fichier \"Dockerfile\" qui décrit les étapes pour créer l'image. Il peut\ninclure des instructions pour copier les fichiers, installer des paquets, définir des variables d'environnement, etc. Les images peuvent\négalement être créées à partir d'autres images existantes en utilisant les instructions \"FROM\" dans un Dockerfile.\n\n\n\nGestion des déploiements : Il est possible de gérer les déploiements avec Docker en utilisant les commandes \"docker service\ncreate\" pour créer un service, \"docker service update\" pour mettre à jour un service, et \"docker service rm\" pour supprimer un\nservice. Il est également possible de gérer les déploiements en utilisant des outils de gestion de configuration tels que Ansible ou\nTerraform qui peuvent automatiser les tâches de déploiement.\n\n\n\nUtilisation des réseaux et des volumes : Les conteneurs peuvent être connectés à des réseaux et des volumes en utilisant les\noptions de la commande \"docker run\" ou en définissant les options de réseau et de volume dans un fichier \"docker-compose.yml\" pour\ngérer les déploiements.",
      "images": []
    },
    {
      "number": 29,
      "content": "TYPES DE RÉSEAUX DANS SWARM\n\n Types de Réseaux\n bridge : Réseau par défaut pour les conteneurs sur un même hôte.\n host : Le conteneur partage la pile réseau de l'hôte.\n none : Aucun réseau n'est attaché au conteneur.\n overlay : Réseau distribué sur plusieurs nœuds Swarm.\n Mode Ingress (par défaut) : Le service est accessible via n'importe quel nœud du Swarm.",
      "images": []
    },
    {
      "number": 30,
      "content": "SERVICE DISCOVERY\n\n Docker Swarm intègre un service de résolution DNS qui permet aux services de se découvrir mutuellement par\n\nleur nom.\n Pour que la découverte fonctionne, les services doivent être sur le même réseau overlay :\n docker network create -d overlay my-app-net\n\n docker service create --name db --network my-app-net mysql\n docker service create --name web --network my-app-net nginx",
      "images": []
    },
    {
      "number": 31,
      "content": "RÉSEAUX OVERLAY DANS DOCKER SWARM\n\n Les réseaux overlay permettent aux conteneurs de différents nœuds de communiquer entre eux.\n\n Création d'un réseau overlay personnalisé :\n docker network create -d overlay my-overlay-net\n\n Attacher un service à un réseau overlay :\n docker service create --name my-service --network my-overlay-net nginx",
      "images": []
    },
    {
      "number": 32,
      "content": "RÉSEAUX OVERLAY DANS DOCKER SWARM\n\nPublier des Ports avec Différents Modes\n Mode Ingress (par défaut) : Le service est accessible via n'importe quel nœud du Swarm.\n docker service create --name my-service -p 80:80 nginx\n Mode Host : Le service est accessible uniquement via le nœud où il s'exécute.\n docker service create --name my-service --network host -p 80:80 nginx",
      "images": []
    },
    {
      "number": 33,
      "content": "OVERLAY (UTILISÉ DANS L'ORCHESTRATION) #SWARM\n\nDans un environnement docker avec 2 hôtes, chaque hôte a 1\nconteneur à l'intérieur :",
      "images": [
        {
          "fileName": "/tmp/pdf-reader/awcqwswcixk/page-33-002.png",
          "content": "(Host 1\n\nDocker\n\n \n\n \n\n \n\ntetcd\n\n \n\n \n \n \n\nContainer 1\n\neth1\n172.18.0.2\n\neth0\n192.168.205.10\n\n   \n\n \n\n \n\n   \n  \n    \n\n \n\n \n\n  \n   \n\nphysical network\n\nnetwork\n\noverla\n\nContainer 2\n\neth1\n172.18.0.2\n\n  \n \n\nDocker_gwbridge\n\neth0\n192.168.205.11"
        },
        {
          "fileName": "/tmp/pdf-reader/awcqwswcixk/page-33-003.png",
          "content": "(CERTES TRE EER UT\nContainer1 : eth0: 10.0.0.2\n\n \n\n(Host) Docker03 : 172.16.255.103\nContaïner2 : eth0: 10.0.0.3"
        }
      ]
    },
    {
      "number": 34,
      "content": "OVERLAY (UTILISÉ DANS L'ORCHESTRATION) #SWARM\n\n\n\nLorsque vous créez un réseau overlay, Docker crée un espace de noms pour le réseau sur l'hôte.\n\n\n\nIl créera ensuite un périphérique de pont (par exemple br0) et une interface vxlan.\n\n\n\nLorsque vous créez un conteneur attaché à ce réseau, il sera attaché au bridge.\n\n\n\nLorsque vous envoyez ensuite du trafic entre les conteneurs sur différents hôtes, le périphérique réseau sur le conteneur l'envoie\nau périphérique vxlan et au pont br0, jusqu'à l'hôte.\n\n\n\nL'hôte utilise l'en-tête vxlan pour acheminer le paquet vers le nœud de destination.\n\n\n\nLa méthode recommandée pour créer un réseau superposé de nos jours se fait en 2 étapes :\n\n1. Créez un réseau swarm entre les nœuds que vous souhaitez mettre en réseau.\n2. Créez un overlay sur le dessus et les nodes de swarm se découvriront automatiquement.\n\nAvant de commencer à créer un réseau superposé à l'aide de Swarm, assurez-vous que les ports suivants sont ouverts et accessibles sur\ntous les nœuds hôtes Docker :\n\n\n\nPort TCP 2377\n\n\n\nPort TCP et UDP 7946\n\n\n\nPort UDP 4789",
      "images": [
        {
          "fileName": "/tmp/pdf-reader/awcqwswcixk/page-34-002.jpg",
          "content": "Docker Host 1\n\n   \n\nDocker Host 2\n\n172.16.255.101\n\n1:\n\n= 172.16.255.103\n7216255101 | Dest:4789"
        }
      ]
    },
    {
      "number": 35,
      "content": "TP PRATIQUE: CRÉATION D'UN CLUSTER SWARM\n\n 1. Créez un cluster avec 3 Managers et 3 Workers.\n 2. Déployez une application multi-services avec Docker Stack.\n 3. Configurez des réseaux overlay, utilisez des configs et testez la découverte de services.\n\n 4. Effectuez une mise à jour d'image et gérez un rollback.",
      "images": []
    },
    {
      "number": 36,
      "content": "\n\nPrendre le compose et déjà créer le .env avec\n\n\n\nles variables indiqués dans le compose\n\n\n\ntransformer ce compose en stakc pour swarm :\n\n\n\n- Ajouter la partie deploy\n\n\n\nBDD: 1 replicas\n\n\n\nFront : 2 replicas\n\n\n\nRedis : 2 replicas\n\n\n\nparalellism : 1\n\n\n\nresources limits\n\n\n\ncontraints\n\n\n\n- BDD sur le master\n\n\n\n- Le reste sur les worker",
      "images": []
    },
    {
      "number": 37,
      "content": "INTRODUCTION À KUBERNETES\n\nVous fournissez à Kubernetes un cluster\nde nœuds qu'il peut utiliser pour exécuter\ndes tâches conteneurisées. Vous indiquez\nà Kubernetes la quantité de CPU et de\nmémoire (RAM) que chaque conteneur a\nbesoin. Kubernetes peut adapter les\nconteneurs sur vos nœuds afin d'utiliser au\nmieux utilisation de vos ressources.\n\nKubernetes redémarre les\nconteneurs qui échouent,\nremplace les conteneurs, tue les\nconteneurs qui ne répondent pas\nà votre contrôle de santé défini\npar l'utilisateur, et ne les annonce\npas aux clients jusqu'à ce qu'ils\nsoient prêts à servir.\n\nVous pouvez décrire l'état souhaité pour\nvos conteneurs déployés en utilisant\nKubernetes, et il peut changer l'état réel\nvers l'état souhaité à une vitesse\ncontrôlée. Par exemple, vous pouvez\nautomatiser Kubernetes pour créer de\nnouveaux conteneurs pour votre\ndéploiement, retirer les conteneurs\nexistants et adopter toutes leurs\nressources vers le nouveau conteneur.\n\nKubernetes vous permet de faire\névoluer facilement vos\napplications manuellement avec\nune simple ligne de commande ou\ndynamiquement sur la base de\nmétriques standard comme le\nCPU et la mémoire, ou sur la\nbase de paramètres personnalisés.\n\nKubernetes vous permet de stocker\net gérer des informations sensibles,\ncomme les mots de passe, les jetons\nOAuth, et les clés ssh. Vous pouvez\ndéployer et mettre à jour les secrets\net la configuration d'application sans\navoir à reconstruire vos images de\nconteneur, et sans exposer les\nsecrets dans votre configuration de la\npile.\n\nKubernetes peut exposer un\nconteneur en utilisant son nom DNS\nou en utilisant sa propre adresse IP.\nSi le trafic vers un conteneur est\nimportant, Kubernetes peut\néquilibrer la charge et distribuer le\ntrafic réseau afin que le déploiement\nsoit stable.",
      "images": [
        {
          "fileName": "/tmp/pdf-reader/awcqwswcixk/page-37-002.png",
          "content": "Intelligent scheduling\n\nYou provide Kubernetes with a\ncluster of nodes that it can use to run\ncontainerized task. You tell\nKubernetes how much CPU and\nmemory (RAM) each container\nneeds. Kubernetes can fit containers\nonto your nodes to make the best\nuse of your resources.\n\n \n\nSelf healing\n\nfail, replaces containers,\n\nuntil they are ready to serve.\n\n \n\n \n\n \n\n==\n\n \n\nKubernetes restarts containers that\n\nkills containers that don't respond to\nyour user-defined health check, and\ndoesn't advertise them to clients\n\nHorizontal scaling\n\nKubernetes allow you to easily scale\nyour applications manually with a\nsimple command line or dynamically\nbased on standard metrics like CPU\nand Memory or with custom metrics.\n\n \n\n \n\n \n\n \n\n \n\n \n\n>\n—\n\n \n\nAutomated Rollout &\nRollback\n\nYou can describe the desired state for\nyour  deployed containers using\nKubernetes, and it can change the\nactual state to the desired state at a\ncontrolled rate. For example, you can\nautomate Kubernetes to create new\ncontainers for your deployment,\nremove existing containers and adopt\nall their resources to the new\ncontainer.\n\n \n\n \n\nSecret & Config\nmanagement\n\nKubernetes lets you store and\nmanage sensitive _ information,\nsuch as passwords, OAuth tokens,\nand ssh keys. You can deploy and\nupdete secrets and application\nconfiguration without rebuilding\nyour container images, and\nwithout exposing secrets in your\nstack configuration.\n\n \n\n \n\n \n\n \n\nService discovery &\nLoad Balancing\n\nKubernetes can expose à container\nusing the DNS name or using their\nown IP address. If traffic to a\ncontainer is high, Kubernetes is able\nto load balance and distribute the\nnetwork traffic so that the\ndeployment is stable:"
        }
      ]
    },
    {
      "number": 38,
      "content": "INTRODUCTION À KUBERNETES",
      "images": [
        {
          "fileName": "/tmp/pdf-reader/awcqwswcixk/page-38-003.jpg",
          "content": "Intelligent scheduling\n\nVous fournissez à Kubernetes un cluster\nde nœuds qu'il peut utiliser pour exécuter\ndes tâches conteneurisées. Vous indiquez\nà Kubernetes la quantité de CPU et de\nmémoire (RAM) que chaque conteneur a\nbesoin. Kubernetes peut adapter les\nconteneurs sur vos nœuds afin d'utiliser au\nmieux utilisation de vos ressources.\n\n \n\n \n\n \n\n \n\nSelf healing\n\nKubernetes redémarre les\nconteneurs qui échouent,\n\nremplace les conteneurs, tue les\n\nconteneurs qui ne répondent pas\nà votre contrôle de santé défini\n\npar l'utilisateur, et ne les annonce\npas aux clients jusqu'à ce qu'ils\n\nsoient prêts à servir.\n\nAutomated Rollout &\nRollback\n\nVous pouvez décrire l'état souhaité pour\nvos conteneurs déployés en utilisant\nKubernetes, et il peut changer l'état réel\nvers l'état souhaité à une vitesse\ncontrôlée. Par exemple, vous pouvez\nautomatiser Kubernetes pour créer de\n\nnouveaux conteneurs pour votre\ndéploiement, retirer les conteneurs\nexistants et adopter toutes leurs\nressources vers le nouveau conteneur.\n\n   \n\n \n\nSE\n\nHorizontal scaling\n\nKubernetes vous permet de faire\névoluer facilement vos\napplications manuellement avec\nune simple ligne de commande ou\ndynamiquement sur la base de\nmétriques standard comme le\nCPU et la mémoire, ou sur la\nbase de paramètres personnalisés.\n\nSecret & Config\n\nmanagement\nKubernetes vous permet de stocker\net gérer des informations sensibles,\ncomme les mots de passe, les jetons\nOAuth, et les clés ssh. Vous pouvez\ndéployer et mettre à jour les secrets\net la configuration d'application sans\navoir à reconstruire vos images de\nconteneur, et sans exposer les\n\nsecrets dans votre configuration de la\npile.\n\n \n\nService discovery &\nLoad Balancing\n\nKubernetes peut exposer un\nconteneur en utilisant son nom DNS\nou en utilisant sa propre adresse IP.\n\nSi le trafic vers un conteneur est\nimportant, Kubernetes peut\néquilibrer la charge et distribuer le\ntrafic réseau afin que le déploiement\nsoit stable."
        }
      ]
    }
  ]
}